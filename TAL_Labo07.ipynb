{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labo 07 \n",
    "\n",
    "#### Jarod Streckeisen - Dimitri De Bleser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import reuters\n",
    "from nltk import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Charger les données Reuters\n",
    "documents = reuters.fileids()\n",
    "categories = ['money-fx', 'grain', 'nat-gas']\n",
    "\n",
    "# Fonction pour extraire le texte des documents\n",
    "def get_text(doc_id):\n",
    "    return reuters.raw(doc_id)\n",
    "\n",
    "# Séparer les données en train et test comme dans NLTK\n",
    "train_docs_id = list(filter(lambda doc: doc.startswith(\"training\"), documents))\n",
    "test_docs_id = list(filter(lambda doc: doc.startswith(\"test\"), documents))\n",
    "\n",
    "train_docs = [get_text(doc_id) for doc_id in train_docs_id]\n",
    "test_docs = [get_text(doc_id) for doc_id in test_docs_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifieurs  binaires\n",
    "\n",
    "#### Choix des hyperparametres test: \n",
    "- Suppression des stopwords → {oui, non} \n",
    "- Représentation des documents → {Bernoulli, multinomiale} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -- Meilleurs hyperparamètres --\n",
      "                  money-fx        grain      nat-gas\n",
      "use_stopwords        False         True         True\n",
      "model_type     Multinomial  Multinomial  Multinomial\n",
      "\n",
      " -- Scores Binaire --\n",
      "           money-fx  grain  nat-gas\n",
      "precision      0.58   0.57     0.55\n",
      "recall         0.98   0.95     0.40\n",
      "f1             0.73   0.71     0.46\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import pandas as pd\n",
    "\n",
    "# Fonction pour obtenir les étiquettes binaires pour une catégorie donnée\n",
    "def get_labels(docs_id, category):\n",
    "    return [1 if category in reuters.categories(doc_id) else 0 for doc_id in docs_id]\n",
    "\n",
    "# Création des étiquettes binaires pour chaque catégorie\n",
    "train_labels = {category: get_labels(train_docs_id, category) for category in categories}\n",
    "test_labels = {category: get_labels(test_docs_id, category) for category in categories}\n",
    "\n",
    "# Définir une fonction pour entraîner et valider les modèles\n",
    "def train_and_evaluate(train_docs, train_labels, test_docs, test_labels, use_stopwords, model_type):\n",
    "    # Vectorisation des textes\n",
    "    stop_words = 'english' if use_stopwords else None\n",
    "    vectorizer = CountVectorizer(stop_words=stop_words, binary=(model_type == 'Bernoulli'))\n",
    "    X_train = vectorizer.fit_transform(train_docs)\n",
    "    X_test = vectorizer.transform(test_docs)\n",
    "    \n",
    "    # Choisir le classifieur\n",
    "    if model_type == 'Multinomial':\n",
    "        model = MultinomialNB()\n",
    "    elif model_type == 'Bernoulli':\n",
    "        model = BernoulliNB()\n",
    "    \n",
    "    model.fit(X_train, train_labels)\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    precision = precision_score(test_labels, predictions, zero_division=0)\n",
    "    recall = recall_score(test_labels, predictions)\n",
    "    f1 = f1_score(test_labels, predictions)\n",
    "    \n",
    "    return precision, recall, f1\n",
    "\n",
    "# Validation croisée pour chaque catégorie\n",
    "best_params = {}\n",
    "for category in categories:\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n",
    "    train_idx, dev_idx = next(sss.split(train_docs, train_labels[category]))\n",
    "    train_docs_cv, dev_docs_cv = np.array(train_docs)[train_idx], np.array(train_docs)[dev_idx]\n",
    "    train_labels_cv, dev_labels_cv = np.array(train_labels[category])[train_idx], np.array(train_labels[category])[dev_idx]\n",
    "    \n",
    "    best_f1 = 0\n",
    "    for use_stopwords in [True, False]:\n",
    "        for model_type in ['Multinomial', 'Bernoulli']:\n",
    "            precision, recall, f1 = train_and_evaluate(train_docs_cv, train_labels_cv, dev_docs_cv, dev_labels_cv, use_stopwords, model_type)\n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                best_params[category] = {'use_stopwords': use_stopwords, 'model_type': model_type}\n",
    "\n",
    "# Entraînement final avec les meilleurs hyperparamètres\n",
    "final_results = {}\n",
    "for category in categories:\n",
    "    params = best_params[category]\n",
    "    precision, recall, f1 = train_and_evaluate(train_docs, train_labels[category], test_docs, test_labels[category], params['use_stopwords'], params['model_type'])\n",
    "    final_results[category] = {'precision': precision, 'recall': recall, 'f1': f1}\n",
    "    \n",
    "# Création du DataFrame pandas\n",
    "best_params_df = pd.DataFrame(best_params)\n",
    "scores_df_binaire = pd.DataFrame(final_results).round(2)\n",
    "\n",
    "# Affichage du tableau\n",
    "print(\" -- Meilleurs hyperparamètres --\")\n",
    "print(best_params_df)\n",
    "print(\"\")\n",
    "print(\" -- Scores Binaire --\")\n",
    "print(scores_df_binaire)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifieur multi-classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Fonction pour obtenir l'étiquette principale pour chaque document\n",
    "def get_primary_label(doc_id):\n",
    "    doc_categories = reuters.categories(doc_id)\n",
    "    for category in categories:\n",
    "        if category in doc_categories:\n",
    "            return category\n",
    "    return 'other'\n",
    "\n",
    "# Créer les étiquettes pour l'entraînement et le test\n",
    "train_primary_labels = [get_primary_label(doc_id) for doc_id in train_docs_id]\n",
    "test_primary_labels = [get_primary_label(doc_id) for doc_id in test_docs_id]\n",
    "\n",
    "# Encodage des étiquettes en entiers\n",
    "label_encoder = LabelEncoder()\n",
    "train_primary_labels_encoded = label_encoder.fit_transform(train_primary_labels)\n",
    "test_primary_labels_encoded = label_encoder.transform(test_primary_labels)\n",
    "\n",
    "# Choix des meilleurs hyperparamètres des classifieurs binaires\n",
    "use_stopwords = True  # basé sur les observations précédentes\n",
    "model_type = 'Multinomial'  # basé sur les observations précédentes\n",
    "\n",
    "# Vectorisation des textes\n",
    "stop_words = 'english' if use_stopwords else None\n",
    "vectorizer = CountVectorizer(stop_words=stop_words, binary=(model_type == model_type))\n",
    "X_train = vectorizer.fit_transform(train_docs)\n",
    "X_test = vectorizer.transform(test_docs)\n",
    "\n",
    "# Entraînement du modèle multi-classe\n",
    "multi_class_model = LogisticRegression(max_iter=1000, random_state=0)\n",
    "multi_class_model.fit(X_train, train_primary_labels_encoded)\n",
    "\n",
    "# Prédiction sur le test set\n",
    "predictions_multi_class = multi_class_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -- Scores multiclasse --\n",
      "            grain  money-fx  nat-gas    other  accuracy  macro avg  \\\n",
      "precision    0.91      0.79     0.71     0.96      0.95       0.84   \n",
      "recall       0.80      0.69     0.40     0.98      0.95       0.72   \n",
      "f1-score     0.85      0.73     0.51     0.97      0.95       0.77   \n",
      "support    148.00    179.00    30.00  2662.00      0.95    3019.00   \n",
      "\n",
      "           weighted avg  \n",
      "precision          0.95  \n",
      "recall             0.95  \n",
      "f1-score           0.95  \n",
      "support         3019.00  \n",
      "\n",
      " -- Scores Binaire --\n",
      "           money-fx  grain  nat-gas\n",
      "precision      0.58   0.57     0.55\n",
      "recall         0.98   0.95     0.40\n",
      "f1             0.73   0.71     0.46\n"
     ]
    }
   ],
   "source": [
    "# Obtenir le rapport de classification\n",
    "report = classification_report(test_primary_labels_encoded, predictions_multi_class, target_names=label_encoder.classes_, output_dict=True)\n",
    "\n",
    "# Création du DataFrame pandas\n",
    "scores_df = pd.DataFrame(report).round(2)\n",
    "\n",
    "# Affichage du tableau\n",
    "print(\" -- Scores multiclasse --\")\n",
    "print(scores_df)\n",
    "print(\"\")\n",
    "print(\" -- Scores Binaire --\")\n",
    "print(scores_df_binaire)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "On peut voir que les scores avec un model multi-classe est superieur au models binaire. La classification multi-classe semble\n",
    "donc etre la bonne strategie. Il est a notee que la classe nat-gas a un score bas, qui peut s'expliquer par une basse representation de la classe dans les donnees."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
